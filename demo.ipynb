{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('Torch': conda)"
  },
  "interpreter": {
   "hash": "649591896ef0a3657f2bdf9205a4ea891d57508e64d07c33876fda621b08139a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS   = 0.001; # the regularization constant\n",
    "sigma = 2**-16; # the kernel width\n",
    "N     = 632;  # number of persons\n",
    "d     = 100;  # number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(0) tensor(631)\n"
     ]
    }
   ],
   "source": [
    "N = 632\n",
    "perm = torch.randperm(N)\n",
    "print(torch.min(perm), torch.max(perm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(2) tensor(631)\ntensor(0) tensor(628)\n"
     ]
    }
   ],
   "source": [
    "idxtrain = perm[:N//2]\n",
    "idxtest = perm[N//2:]\n",
    "print(torch.min(idxtrain), torch.max(idxtrain))\n",
    "print(torch.min(idxtest), torch.max(idxtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"viper//viper_features.npy\"\n",
    "mat = np.load(file_name, allow_pickle=True)\n",
    "idxa = torch.from_numpy((mat.item().get('idxa')-1).astype('int64'))\n",
    "idxb = torch.from_numpy((mat.item().get('idxb')-1).astype('int64'))"
   ]
  },
  {
   "source": [
    "### first_ind is our set of similiaraity constraints so what we're doing is since idxtrain is a random permutation of 0:631 in 316 elements which act as indexes for the idxa thing and since we are talking 'bout Similaity pairwise constraint hence we're concatinating similiar element in pair e.g. let idxtrain = [[0, 345, 123]] be in R3 then idxa[0, idxtrain] = [x1, x2, x3] then first_ind = [[(x1, x2, x3), (x1, x2, x3)]] pairs. and since in D we want dissimmilar pairs hence we're randomly permutating them for the second phase of cat. e.g. second_ind =[idxb[[0, idxtrain]], idxb[[0, randperm(idxtrain)]]]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 100\n",
    "X = torch.from_numpy(mat.item().get('ux'))[:d, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([100, 1264])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from demo import ret_logical, change_view\n",
    "matches = ret_logical(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_ind = change_view(torch.cat((idxa[0, idxtrain], idxa[0, idxtrain])))\n",
    "second_ind = change_view(torch.cat((idxb[0, idxtrain], idxb[0, idxtrain[torch.randperm(N//2)]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = torch.cat((first_ind[:, matches], second_ind[:, matches])) # must-link constraints\n",
    "D = torch.cat((first_ind[:, torch.logical_not(matches)], second_ind[:, torch.logical_not(matches)])) # cannot-link constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor(442), tensor(1074))"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "S[0, 0], S[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1264, 1264])\n"
     ]
    }
   ],
   "source": [
    "from kernelmatrix import kernelmatrix\n",
    "K = kernelmatrix(X, X2=torch.tensor([]), sigma=sigma)\n",
    "print(K.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from computeH import computeH\n",
    "n = K.shape[0]\n",
    "n1 = S.shape[1]\n",
    "n0 = D.shape[1]\n",
    "H0 = computeH(n, D[0, :], D[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1.,\n",
       "        1., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
       "        0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0.,\n",
       "        1., 1., 1., 0., 0., 1., 1., 1., 1., 1.])"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "torch.diagonal(H0)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}