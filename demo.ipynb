{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('Torch_CPU': conda)"
  },
  "interpreter": {
   "hash": "eaa354cd4f75d0690ab6840a8f07dcb5985fa9403c4f9b9a14a79eacd5a5322f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS   = 0.001; # the regularization constant\n",
    "sigma = 2**-16; # the kernel width\n",
    "N     = 632;  # number of persons\n",
    "d     = 100;  # number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(0) tensor(631)\n"
     ]
    }
   ],
   "source": [
    "N = 632\n",
    "perm = torch.randperm(N)\n",
    "print(torch.min(perm), torch.max(perm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(0) tensor(627)\ntensor(5) tensor(631)\n"
     ]
    }
   ],
   "source": [
    "idxtrain = perm[:N//2]\n",
    "idxtest = perm[N//2:]\n",
    "print(torch.min(idxtrain), torch.max(idxtrain))\n",
    "print(torch.min(idxtest), torch.max(idxtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"viper//viper_features.npy\"\n",
    "mat = np.load(file_name, allow_pickle=True)\n",
    "idxa = torch.from_numpy((mat.item().get('idxa')-1).astype('int64'))\n",
    "idxb = torch.from_numpy((mat.item().get('idxb')-1).astype('int64'))"
   ]
  },
  {
   "source": [
    "# first_ind is our set of similiaraity constraints so what we're doing is since idxtrain is a random permutation of 0:631 in 316 elements which act as indexes for the idxa thing and since we are talking 'bout Similaity pairwise constraint hence we're concatinating similiar element in pair e.g. let idxtrain = [[0, 345, 123]] be in R3 then idxa[0, idxtrain] = [x1, x2, x3] then first_ind = [[x1, x2, x3], [x1, x2, x3]] pairs. and since in D we want dissimmilar pairs hence we're randomly permutating them for the second phase of cat. e.g. second_ind = [idxb[[0, idxtrain]], idxb[0, randperm(idxtrain)]]"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 100\n",
    "X = torch.from_numpy(mat.item().get('ux'))[:d, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([100, 1264])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from demo import ret_logical, change_view\n",
    "matches = ret_logical(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_ind = change_view(torch.cat((idxa[0, idxtrain], idxa[0, idxtrain])))\n",
    "second_ind = change_view(torch.cat((idxb[0, idxtrain], idxb[0, idxtrain[torch.randperm(N//2)]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = torch.cat((first_ind[:, matches], second_ind[:, matches])) # must-link constraints\n",
    "D = torch.cat((first_ind[:, torch.logical_not(matches)], second_ind[:, torch.logical_not(matches)])) # cannot-link constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor(0), tensor(627), tensor(632), tensor(1259))"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "torch.min(S[0,:]), torch.max(S[0,:]), torch.min(S[1,:]), torch.max(S[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor(224), tensor(856))"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "S[0, 0], S[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1264, 1264])\n"
     ]
    }
   ],
   "source": [
    "from kernelmatrix import kernelmatrix\n",
    "K = kernelmatrix(X, X2=torch.tensor([]), sigma=sigma)\n",
    "print(K.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from computeH import computeH\n",
    "n = K.shape[0]\n",
    "n1 = S.shape[1]\n",
    "n0 = D.shape[1]\n",
    "H0 = computeH(n, D[0, :], D[1, :])\n",
    "H1 = computeH(n, S[0, :], S[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = torch.zeros(n, 1)\n",
    "E = torch.zeros(n, 1)\n",
    "W = torch.zeros(n, n)\n",
    "ib, ie = S[0, :], S[1, :]\n",
    "o = torch.ones(ib.shape[0], 1)\n",
    "B[ib] = o\n",
    "E[ie] = o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(627) tensor(1259) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "def Calc_W(ib, ie, W):\n",
    "\n",
    "    for i in range(0, ib.shape[0]):\n",
    "        W[ib[i], ie[i]] = W[ib[i], ie[i]] + 1\n",
    "        \n",
    "    return W\n",
    "W = Calc_W(ib, ie, W)\n",
    "print(torch.max(ib), torch.max(ie), W[torch.max(ib), torch.max(ie)]\n",
    ")"
   ]
  },
  {
   "source": [
    "### Caluclate $\\Sigma_{1} = (\\frac{1}{n1})XH_{1}X^T$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_a = torch.mm(X.double(), H1.double())\n",
    "temp_b = torch.mm(temp_a, X.T)\n",
    "Sigma1 = (1/S.shape[1])*temp_b\n",
    "\n",
    "# Similarly calculate Sigma0\n",
    "Sigma0 = (1/D.shape[1])*torch.mm(torch.mm(X.double(), H0.double()), X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma1_inv = torch.inverse(Sigma1)\n",
    "Sigma0_inv = torch.inverse(Sigma0)\n",
    "M_ = Sigma1_inv - Sigma0_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1264, 1264)\n"
     ]
    }
   ],
   "source": [
    "from helps.kernel import kernel\n",
    "M = kernel(0.001, S, D, K, 1)\n",
    "print(M.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('M.npy', M.numpy())\n",
    "# np.save('idxa.npy', idxa.numpy())\n",
    "# np.save('idxb.npy', idxb.numpy())\n",
    "# np.save('idxtest.npy', idxtest.numpy())\n",
    "# np.save('idxtrain.npy', idxtrain.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it hints that if there is some problem it is inside computeT function because CalcMCMC is just doing one thing which is to calculate Mahalanobis distance, it might be that the problem is in CalcMCMC but it will be our last resort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([3, 3])\ntensor([[0.1690, 0.9585, 0.1626],\n        [0.4663, 0.7948, 0.3751],\n        [0.4075, 0.0106, 0.3731]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[0.169019, 0.958515, 0.162583], [0.466288, 0.794831, 0.375050], [0.407539, 0.010616, 0.373111]])\n",
    "print(x.shape)\n",
    "print(x.double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, V = torch.eig(x, eigenvectors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 1.3417,  0.0000],\n        [-0.1323,  0.0000],\n        [ 0.1276,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-0.6312, -0.7725, -0.5098],\n        [-0.7258,  0.1377, -0.1224],\n        [-0.2735,  0.6199,  0.8516]])\n"
     ]
    }
   ],
   "source": [
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000])"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "torch.norm(V, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor(5), tensor(631), tensor(0), tensor(627))"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "torch.min(idxtest), torch.max(idxtest), torch.min(idxtrain), torch.max(idxtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor(5), tensor(631))"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "torch.min(idxa[:, idxtest]), torch.max(idxa[:, idxtest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxa = idxa.view(idxa.shape[1])\n",
    "idxb = idxb.view(idxb.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = K\n",
    "p = data[:, idxa[idxtest]]\n",
    "q = data[:, idxb[idxtest]]"
   ]
  },
  {
   "source": [
    "### Compute the Mahalanobis distance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "A =  K\n",
    "(d, pn) = p.shape\n",
    "(d, qn) = q.shape\n",
    "Ap = torch.mm(A.double(), p)\n",
    "Aq = torch.mm(A.double(), q)\n",
    "pmag = torch.sum(p*Ap, 0, keepdim=True).double()\n",
    "qmag = torch.sum(q*Aq, 0, keepdim=True).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = torch.mm(torch.ones(pn, 1).double(), qmag) + torch.mm(pmag.T, torch.ones(1, qn).double()) - 2 * torch.mm(p.T, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = torch.zeros(1, dist.shape[1])\n",
    "for pairCounter in range(0, dist.shape[1]):\n",
    "    distPair = dist[pairCounter, :]\n",
    "    tmp, idx = torch.sort(distPair)\n",
    "    result[:, idx==pairCounter] = result[:, idx==pairCounter] + 1\n",
    "\n",
    "tmp = 0\n",
    "for counter in range(1, result.shape[0]):\n",
    "    result[:, counter] = result[:, counter] + tmp\n",
    "    tmp = result[:, counter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([ 1.8613818 , -0.41706017,  0.04769045], dtype=float32),\n",
       " array([[-0.5295369 , -0.629563  , -0.01616446],\n",
       "        [-0.5056032 ,  0.7722581 , -0.90522945],\n",
       "        [-0.6811432 ,  0.0852519 ,  0.42461553]], dtype=float32))"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.linalg.eig(torch.rand(3,3).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[0.870188 , 0.111200 , 0.185495],\n",
    "   [0.791261 , 0.514741 , 0.037194],\n",
    "   [0.392026 , 0.209612 , 0.270831]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1.15225668 0.25175166 0.25175166]\nfloat64\n"
     ]
    }
   ],
   "source": [
    "d, v = np.linalg.eig(x)\n",
    "d = np.real(d)\n",
    "v = np.real(v)\n",
    "print(d)\n",
    "print(d.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2.22044605e-16 2.51751661e-01 2.51751661e-01]\n"
     ]
    }
   ],
   "source": [
    "d[0] = -13\n",
    "d[d<0] = np.finfo(np.float64).eps\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from helps.projectPSD import projectPSD\n",
    "# D = projectPSD(M)\n",
    "# d = np.copy(D)\n",
    "# print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d[d<=0] = np.finfo(np.float64).eps\n",
    "# for i in range(0, D.shape[0]):\n",
    "#     print(D[i], d[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from helps.projectPSD import projectPSD\n",
    "# # d, V = projectPSD(M)\n",
    "# M = projectPSD(M)\n",
    "# # print(d.shape, V.shape)\n",
    "# print(M.shape)\n",
    "# print(np.diagonal(M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = torch.from_numpy(np.load('M.npy'))\n",
    "idxtest = torch.from_numpy(np.load('idxtest.npy'))\n",
    "idxtrain = torch.from_numpy(np.load('idxtrain.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-342.5669,  293.3381,    0.0000,  ...,    0.0000,    0.0000,\n",
       "        -120.3820], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "torch.diagonal(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helps.projectPSD import projectPSD\n",
    "M_ = torch.from_numpy(projectPSD(M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([9.4923e+02, 8.9512e+02, 2.2204e-16, 1.0735e+03, 8.2489e+02, 9.7003e+02,\n",
       "        2.2204e-16, 8.7572e+02, 9.6203e+02, 2.2204e-16, 1.1507e+03, 9.2933e+02,\n",
       "        9.0402e+02, 9.8201e+02, 1.0828e+03, 2.2204e-16, 2.2204e-16, 8.7227e+02,\n",
       "        2.2204e-16, 9.8913e+02, 1.0689e+03, 2.2204e-16, 2.2204e-16, 2.2204e-16,\n",
       "        9.0687e+02, 2.2204e-16, 2.2204e-16, 6.5718e+02, 2.2204e-16, 2.2204e-16,\n",
       "        2.2204e-16, 2.2204e-16, 2.2204e-16, 2.2204e-16, 2.2204e-16, 1.1465e+03,\n",
       "        2.2204e-16, 1.2879e+03, 1.1283e+03, 1.1166e+03, 2.2204e-16, 2.2204e-16,\n",
       "        1.1469e+03, 2.2204e-16, 9.3253e+02, 8.8699e+02, 2.2204e-16, 2.2204e-16,\n",
       "        8.7405e+02, 9.4235e+02, 2.2204e-16, 1.2192e+03, 9.3546e+02, 8.9555e+02,\n",
       "        2.2204e-16, 1.0933e+03, 2.2204e-16, 1.0751e+03, 2.2204e-16, 1.2869e+03,\n",
       "        8.3605e+02, 2.2204e-16, 1.1565e+03, 1.0362e+03, 8.4100e+02, 2.2204e-16,\n",
       "        1.0771e+03, 2.2204e-16, 8.6608e+02, 7.1336e+02, 2.2204e-16, 2.2204e-16,\n",
       "        2.2204e-16, 1.0066e+03, 2.2204e-16, 2.2204e-16, 7.2128e+02, 2.2204e-16,\n",
       "        2.2204e-16, 2.2204e-16, 2.2204e-16, 2.2204e-16, 7.4486e+02, 2.2204e-16,\n",
       "        9.9709e+02, 2.2204e-16, 7.4287e+02, 2.2204e-16, 8.3022e+02, 2.2204e-16,\n",
       "        9.8955e+02, 9.9846e+02, 2.2204e-16, 9.7812e+02, 1.0395e+03, 2.2204e-16,\n",
       "        2.2204e-16, 2.2204e-16, 9.2247e+02, 2.2204e-16], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "torch.diagonal(M_)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helps.sqdist import mahalanobis_dist\n",
    "data = K\n",
    "p = data[:, idxa[idxtest]]\n",
    "p = p.view(p.shape[0], -1)\n",
    "q = data[:, idxb[idxtest]]\n",
    "q = q.view(q.shape[0], -1)\n",
    "# dist = mahalanobis_dist(p, q, M_)\n",
    "A = M_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = kernelmatrix(X=X, X2=torch.tensor([]), sigma=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.4420, dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "K[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ap = torch.mm(A.double(), p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(-161.7417, dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "A[0, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(56.7630, dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "X[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([309, 258, 603, 254, 464,  56,  30, 298, 367, 142, 128,  80, 575, 304,\n",
       "        260,  78, 216,  79, 347, 134, 301, 478, 334, 541, 551, 136, 371, 542,\n",
       "          2, 147,  99,  43, 117, 543,  16, 391, 627, 545, 404, 199, 480, 442,\n",
       "        303, 228, 240,  23, 422, 305, 141,   9, 619, 380, 289, 599, 454, 423,\n",
       "        594, 279, 139, 212, 188,  89, 353, 101,  29,  34, 374, 124, 329, 359,\n",
       "        513, 221,  25, 346,  36, 327, 506, 311, 405, 297, 257, 537, 370, 624,\n",
       "        466, 325, 628, 266, 432, 433, 584, 316, 290, 378,  26, 192, 589, 416,\n",
       "        159, 180, 246, 570, 414,  28, 467, 450, 295, 291, 218, 494, 270, 523,\n",
       "         81,  58,  47, 312, 168, 244, 195, 360,  21, 226,   6, 472,  33, 386,\n",
       "        288, 227, 397, 401, 400, 591, 277, 413, 527, 324, 439,  70, 593, 208,\n",
       "        217, 364, 460, 349, 451, 418,  32, 438, 255, 157, 508, 588, 179, 426,\n",
       "        622, 336, 264, 273, 598, 234, 151, 213, 173, 131, 424, 175, 602, 623,\n",
       "        210, 565, 437,  46, 547, 318, 488, 275, 122, 201, 174, 578, 626,  92,\n",
       "        251, 271, 261, 630, 278,  31, 629, 555,  87, 389,  65,  74, 621, 143,\n",
       "         96, 517, 337, 365, 333, 402, 112,  72, 431, 392, 446, 150, 616, 456,\n",
       "        511, 152, 396, 163,  40, 296, 548,  61,  77,  97, 601, 532, 566, 145,\n",
       "        328, 375, 368,  18, 540, 381, 435, 207, 351, 162, 608, 249,  54, 501,\n",
       "         85, 609, 239,  67, 252, 564, 430, 518, 310, 184, 407, 459, 259, 357,\n",
       "        496, 135, 245, 567,  95, 302,  75, 499, 130, 411, 203, 436, 100, 562,\n",
       "         22, 358, 125, 470, 202,  41, 441, 137, 171, 568,  50, 377, 242, 425,\n",
       "        306, 331, 110, 196, 452, 557, 118, 372, 238, 116, 560, 149, 319, 596,\n",
       "         15, 390, 356, 419, 406, 493, 185, 315, 286,  83, 308, 206, 536, 253,\n",
       "        573, 345, 172, 455, 611, 606,  71, 486])"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "idxtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(0.4873, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "p = data[:, idxa[idxtest]]\n",
    "q = data[:, idxb[idxtest]]\n",
    "print(q[0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ap = torch.mm(A.double(), p)\n",
    "Aq = torch.mm(A.double(), q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmag = torch.sum(p*Ap, 0, keepdim=True).double()\n",
    "qmag = torch.sum(q*Aq, 0, keepdim=True).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.mm(torch.ones(pn, 1).double(), qmag) + torch.mm(pmag.T, torch.ones(1, qn).double()) - 2 * torch.mm(p.T, Aq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(299.8538, dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "m[0, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No problem in Ap, Aq, pmag, qmag as well as M, K thus check for 2 lines above code or sqdist line 23 code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = mahalanobis_dist(p, q, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor(411.9349, dtype=torch.float64), tensor(411.9349, dtype=torch.float64))"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "dist[0, 11], m[0, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(411.9349, dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "from helps.sqdist import mahalanobis_dist\n",
    "x = mahalanobis_dist(p, q, A)\n",
    "x[0, 11]"
   ]
  },
  {
   "source": [
    "### thus by far now sqdist is also working properly, there was a small writing error, wrote q instead of Aq in 2*p'*Aq section "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = 0\n",
    "result = torch.zeros(1, dist.shape[1])\n",
    "for pairCounter in range(0, dist.shape[1]):\n",
    "    distPair = dist[pairCounter, :]\n",
    "    tmp, idx = torch.sort(distPair)\n",
    "    result[:, idx==pairCounter] = result[:, idx==pairCounter] + 1\n",
    "\n",
    "tmp = 0\n",
    "for counter in range(0, result.shape[1]):\n",
    "    result[:, counter] = result[:, counter] + tmp\n",
    "    tmp = result[:, counter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([69.])\ntensor([23.])\ntensor([19.])\ntensor([11.])\ntensor([11.])\ntensor([5.])\ntensor([6.])\ntensor([4.])\ntensor([9.])\ntensor([6.])\ntensor([11.])\ntensor([1.])\ntensor([6.])\ntensor([3.])\ntensor([7.])\ntensor([4.])\ntensor([6.])\ntensor([2.])\ntensor([1.])\ntensor([1.])\ntensor([3.])\ntensor([3.])\ntensor([3.])\ntensor([2.])\ntensor([3.])\ntensor([5.])\ntensor([3.])\ntensor([2.])\ntensor([2.])\ntensor([0.])\ntensor([2.])\ntensor([4.])\ntensor([3.])\ntensor([3.])\ntensor([3.])\ntensor([2.])\ntensor([4.])\ntensor([3.])\ntensor([1.])\ntensor([1.])\ntensor([0.])\ntensor([1.])\ntensor([1.])\ntensor([0.])\ntensor([1.])\ntensor([1.])\ntensor([0.])\ntensor([1.])\ntensor([1.])\ntensor([0.])\ntensor([0.])\ntensor([1.])\ntensor([3.])\ntensor([1.])\ntensor([1.])\ntensor([2.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([1.])\ntensor([0.])\ntensor([4.])\ntensor([2.])\ntensor([2.])\ntensor([0.])\ntensor([0.])\ntensor([3.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([1.])\ntensor([1.])\ntensor([0.])\ntensor([1.])\ntensor([0.])\ntensor([2.])\ntensor([1.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([1.])\ntensor([1.])\ntensor([0.])\ntensor([1.])\ntensor([1.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([1.])\ntensor([2.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([1.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([1.])\ntensor([1.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([1.])\ntensor([1.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([3.])\ntensor([0.])\ntensor([1.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([1.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([1.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([2.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([1.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([1.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([1.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([1.])\ntensor([1.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([1.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([1.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\ntensor([0.])\n"
     ]
    }
   ],
   "source": [
    "tmp = 0\n",
    "for counter in range(0, result.shape[1]):\n",
    "    print(result[:, counter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}