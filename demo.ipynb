{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('Torch_clone': conda)"
  },
  "interpreter": {
   "hash": "469c65de2db8cea275420e7d79b33142baa0cf05ead15a9928307428e2642c66"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 4, 10, 13],\n",
       "        [11, 25, 22]])"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import torch\n",
    "  \n",
    "mat_1 = torch.tensor([[1, 2],\n",
    "                      [4, 3]])\n",
    "  \n",
    "mat_2 = torch.tensor([[2, 4, 1],\n",
    "                      [1, 3, 6]])\n",
    "  \n",
    "torch.mm(mat_1, mat_2, out=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.load(\"viper//viper_features.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 0.001 # the regularization constant\n",
    "sigma = 2**-16 # the kernel width\n",
    "N = 632 # number of persons\n",
    "d = 100 # number of features"
   ]
  },
  {
   "source": [
    "## pre-processing and fine-tunning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'numpy.ndarray'>\n{'ux': array([[ 5.67629517e+01, -3.63088035e+01,  4.58856603e+01, ...,\n         1.19065079e+02,  5.73964714e+01,  2.08629016e+01],\n       [-2.16393607e+01,  8.44310102e+01,  1.81055478e+01, ...,\n        -6.54509105e+00, -2.78207790e+01, -6.40219349e+01],\n       [-2.68692832e+01,  1.55323472e+01,  6.69187222e+01, ...,\n        -7.23177187e+01,  4.59661102e+01, -1.50214244e+01],\n       ...,\n       [-3.24024735e+00, -1.89654954e+00, -1.30103093e+00, ...,\n        -4.19538924e+00, -5.15785784e-01,  1.41844041e+00],\n       [ 6.46609527e+00, -7.96276506e-01,  2.15312450e-01, ...,\n        -4.04320359e+00, -1.44065123e-02,  2.99228625e+00],\n       [ 2.49512733e+00,  6.04396979e-01, -3.69196550e+00, ...,\n         3.58077718e+00, -9.89024863e-01, -4.05953108e+00]]), 'idxa': array([[  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n         27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n         40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n         53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n         66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n         79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n         92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n        105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n        118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n        131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n        144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156,\n        157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,\n        170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n        183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208,\n        209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221,\n        222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234,\n        235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n        248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260,\n        261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273,\n        274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286,\n        287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299,\n        300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312,\n        313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338,\n        339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n        352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n        365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390,\n        391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403,\n        404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416,\n        417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429,\n        430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442,\n        443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455,\n        456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468,\n        469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n        482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n        495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507,\n        508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520,\n        521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533,\n        534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546,\n        547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559,\n        560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572,\n        573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585,\n        586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598,\n        599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611,\n        612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624,\n        625, 626, 627, 628, 629, 630, 631, 632]], dtype=uint16), 'idxb': array([[ 633,  634,  635,  636,  637,  638,  639,  640,  641,  642,  643,\n         644,  645,  646,  647,  648,  649,  650,  651,  652,  653,  654,\n         655,  656,  657,  658,  659,  660,  661,  662,  663,  664,  665,\n         666,  667,  668,  669,  670,  671,  672,  673,  674,  675,  676,\n         677,  678,  679,  680,  681,  682,  683,  684,  685,  686,  687,\n         688,  689,  690,  691,  692,  693,  694,  695,  696,  697,  698,\n         699,  700,  701,  702,  703,  704,  705,  706,  707,  708,  709,\n         710,  711,  712,  713,  714,  715,  716,  717,  718,  719,  720,\n         721,  722,  723,  724,  725,  726,  727,  728,  729,  730,  731,\n         732,  733,  734,  735,  736,  737,  738,  739,  740,  741,  742,\n         743,  744,  745,  746,  747,  748,  749,  750,  751,  752,  753,\n         754,  755,  756,  757,  758,  759,  760,  761,  762,  763,  764,\n         765,  766,  767,  768,  769,  770,  771,  772,  773,  774,  775,\n         776,  777,  778,  779,  780,  781,  782,  783,  784,  785,  786,\n         787,  788,  789,  790,  791,  792,  793,  794,  795,  796,  797,\n         798,  799,  800,  801,  802,  803,  804,  805,  806,  807,  808,\n         809,  810,  811,  812,  813,  814,  815,  816,  817,  818,  819,\n         820,  821,  822,  823,  824,  825,  826,  827,  828,  829,  830,\n         831,  832,  833,  834,  835,  836,  837,  838,  839,  840,  841,\n         842,  843,  844,  845,  846,  847,  848,  849,  850,  851,  852,\n         853,  854,  855,  856,  857,  858,  859,  860,  861,  862,  863,\n         864,  865,  866,  867,  868,  869,  870,  871,  872,  873,  874,\n         875,  876,  877,  878,  879,  880,  881,  882,  883,  884,  885,\n         886,  887,  888,  889,  890,  891,  892,  893,  894,  895,  896,\n         897,  898,  899,  900,  901,  902,  903,  904,  905,  906,  907,\n         908,  909,  910,  911,  912,  913,  914,  915,  916,  917,  918,\n         919,  920,  921,  922,  923,  924,  925,  926,  927,  928,  929,\n         930,  931,  932,  933,  934,  935,  936,  937,  938,  939,  940,\n         941,  942,  943,  944,  945,  946,  947,  948,  949,  950,  951,\n         952,  953,  954,  955,  956,  957,  958,  959,  960,  961,  962,\n         963,  964,  965,  966,  967,  968,  969,  970,  971,  972,  973,\n         974,  975,  976,  977,  978,  979,  980,  981,  982,  983,  984,\n         985,  986,  987,  988,  989,  990,  991,  992,  993,  994,  995,\n         996,  997,  998,  999, 1000, 1001, 1002, 1003, 1004, 1005, 1006,\n        1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017,\n        1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028,\n        1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039,\n        1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050,\n        1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061,\n        1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072,\n        1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083,\n        1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094,\n        1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105,\n        1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116,\n        1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127,\n        1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138,\n        1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149,\n        1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160,\n        1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171,\n        1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182,\n        1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193,\n        1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204,\n        1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215,\n        1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226,\n        1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237,\n        1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248,\n        1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,\n        1260, 1261, 1262, 1263, 1264]], dtype=uint16)}\n"
     ]
    }
   ],
   "source": [
    "print(type(mat))\n",
    "print(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'numpy.ndarray'>\nuint16\n<class 'numpy.ndarray'>\nuint16\n"
     ]
    }
   ],
   "source": [
    "idxa = mat.item().get('idxa')\n",
    "print(type(idxa))\n",
    "print(idxa.dtype)\n",
    "\n",
    "idxb = mat.item().get('idxb')\n",
    "print(type(idxb))\n",
    "print(idxa.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'numpy.ndarray'>\nfloat64\n<class 'numpy.ndarray'>\nfloat64\n"
     ]
    }
   ],
   "source": [
    "idxa = idxa.astype('float64')\n",
    "print(type(idxa))\n",
    "print(idxa.dtype)\n",
    "\n",
    "idxb = idxb.astype('float64')\n",
    "print(type(idxb))\n",
    "print(idxb.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'torch.Tensor'>\ntorch.float64\n<class 'torch.Tensor'>\ntorch.float64\n"
     ]
    }
   ],
   "source": [
    "# Convert numpy.ndarray -> torch.tensor\n",
    "idxa = torch.from_numpy(idxa) # index of images in the first set \n",
    "print(type(idxa))\n",
    "print(idxa.dtype)\n",
    "\n",
    "idxb = torch.from_numpy(idxb) # index of images in the second set\n",
    "print(type(idxb))\n",
    "print(idxb.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'torch.Tensor'>\ntorch.float64\ntorch.Size([100, 1264])\n"
     ]
    }
   ],
   "source": [
    "X = mat.item().get('ux')[:d, :] # numpy.ndarray\n",
    "X = torch.from_numpy(X) # torch.tensor\n",
    "print(type(X))\n",
    "print(X.dtype)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "First Set(shape):  torch.Size([1, 632])\nSecond Set(shape):  torch.Size([1, 632])\nDataset(shape):  torch.Size([100, 1264])\n"
     ]
    }
   ],
   "source": [
    "print(\"First Set(shape): \", idxa.shape)\n",
    "print(\"Second Set(shape): \", idxb.shape)\n",
    "print(\"Dataset(shape): \", X.shape)"
   ]
  },
  {
   "source": [
    "## initilaizing hyper-parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([632])\ntensor([ 24, 457, 587, 166, 337, 583,  87, 501,  82, 613, 460, 424, 541, 264,\n        360, 387,  26, 279, 117, 429, 340, 475, 139,  35, 282,  60, 246, 126,\n        437, 306, 281, 441, 526, 374, 379, 378, 103,  53, 600,  97, 466, 295,\n        618, 418, 248, 576, 235, 628, 480, 472,   1, 436, 525, 498, 325, 411,\n        163, 447, 111, 506, 616, 136, 153, 263, 317,  64, 329, 389, 399, 620,\n        519, 110, 496, 187, 524, 345, 356, 551, 442,  19, 192, 377,  12,  29,\n        209, 390, 189, 211, 608, 183, 614, 104, 224,  92, 611, 549, 398, 230,\n         51, 567, 561, 319, 563, 128, 477, 585, 167, 539, 330, 314, 461, 542,\n        486, 115, 284,  79, 257, 454, 359, 423,   5, 236, 370, 350, 514, 244,\n        232, 206,  58, 133, 438, 219, 520, 333,  33, 138, 300, 289, 450, 276,\n        361, 347, 369, 165, 125, 250, 278, 193, 154, 615,  39,   0, 255, 321,\n        131, 493, 452, 504, 619, 171,  20, 502, 203, 297, 358, 603, 527, 261,\n        462, 580, 538, 529, 531, 445,  54, 455, 395, 484, 407, 174, 499, 433,\n         66, 228, 621, 550, 109,  91, 434, 342,  78, 310, 198,  45, 471, 190,\n        591, 490, 129, 476, 105,  90, 273, 478,  52, 414, 141, 397, 309, 152,\n        234, 371, 130, 242, 568, 253, 627,  85, 127,  23, 446, 213,  16, 304,\n        124, 394, 180, 606, 413, 210, 570, 386,  15, 338, 100, 229, 135, 274,\n         22, 593,  57, 169, 572, 140, 581, 534, 268, 365, 612, 617, 380,  30,\n        218, 364, 247, 155, 112, 164, 299,  13, 175, 196,  37, 116, 160, 535,\n        195, 272,  47, 158, 266, 495, 332, 497, 283,  70, 571,  89, 186, 285,\n        406, 590, 552, 249, 543, 346, 156, 467, 518, 294, 573,  95, 134,  41,\n         36, 595, 197, 137, 184, 470, 217, 204, 181, 547, 106,  67,  43, 566,\n        173,  80, 148, 292, 602, 312, 252, 528,  93,  46,  28,  18, 191, 609,\n          3,  17,  48,  62, 410, 521, 231,  55, 604, 599, 348, 417, 598,  68,\n        123, 290, 324, 625, 149, 624, 372, 233, 254, 375, 430, 151, 245, 178,\n        367, 511,  71, 439,  25, 464, 385,  99, 569, 487, 492, 366, 208, 404,\n        298, 185, 545, 448, 339, 420, 463, 327, 548, 597, 557, 426, 212, 419,\n        344, 449,  27, 376, 220, 623, 554, 313, 328, 403, 489,  65,  14, 553,\n         83, 147, 458, 308, 456,  96, 262, 143, 200, 565, 341, 555, 584, 335,\n        579, 323, 562, 459, 546, 451, 427,   9, 473, 121, 307, 176, 170,  69,\n        402, 384, 503, 532,  86, 238, 188, 270, 336, 479, 517, 114, 605, 331,\n        444, 382, 507, 408, 558, 415, 432,  32,  38, 425, 401, 291, 368, 443,\n        120, 161,  49, 201, 610, 575, 271, 227, 626, 469, 349, 393, 293, 353,\n        144,  42, 146, 416, 422, 578, 465,  74, 194,  61, 488, 118, 101, 303,\n        222, 400, 221, 409, 243, 311, 421,  31,  98, 596, 630, 301, 513, 601,\n        381, 512,  59, 564, 589, 108, 205, 286, 515,  77, 435, 485, 258, 560,\n        305,  75, 491,   2, 522, 388, 574,  44, 119, 199,  21,  72, 582, 428,\n        216, 162, 256, 259, 362, 500, 241, 343, 237, 280, 357, 287, 483, 316,\n         73,  84,   7, 168, 523, 315, 396, 102, 412, 391, 351,  11,  81, 275,\n        508, 533, 354, 536, 215, 355, 182, 132, 373, 320,  34, 440, 150, 594,\n        509, 265, 326, 431, 540,   4, 172, 107, 322, 468, 622, 629,  40,   6,\n        145, 288, 226, 296, 179, 586,  88, 577, 607, 267, 453, 405, 240, 481,\n        214, 559, 157, 482, 277, 494, 392, 510,   8,  94, 239, 383, 516, 223,\n        556, 592,  56, 530, 142, 207, 177,  50, 225,  63, 202, 122, 537, 631,\n        544, 505, 352,  10, 159, 302, 334,  76, 363, 269, 588, 113, 251, 318,\n        260, 474])\n"
     ]
    }
   ],
   "source": [
    "# Draw random permutation\n",
    "perm = torch.randperm(N)\n",
    "print(perm.shape)\n",
    "print(perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([316])\n"
     ]
    }
   ],
   "source": [
    "# split in equal-sized train and test sets\n",
    "idxtrain = perm[:N//2]\n",
    "idxtest = perm[N//2+1:]\n",
    "print(idxtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Transpose image sets \n",
    "# idxa = torch.transpose(idxa, 0, 1)\n",
    "# idxb = torch.transpose(idxb, 0, 1)\n",
    "# print(idxa.shape, idxb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([632])\n"
     ]
    }
   ],
   "source": [
    "# BEGIN k-kissme\n",
    "first_ind = torch.cat((idxa[0,idxtrain], idxa[0,idxtrain]))\n",
    "second_ind = torch.cat((idxb[0,idxtrain], idxb[0,idxtrain[torch.randperm(N//2)]]))\n",
    "print(first_ind.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 632])"
      ]
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "source": [
    "idxa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([632])\n"
     ]
    }
   ],
   "source": [
    "first_ind = torch.cat((idxa[0, idxtrain], idxa[0, idxtrain]))\n",
    "print(first_ind.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_ind = first_ind.view(1, first_ind.shape[0])\n",
    "second_ind = second_ind.view(1, second_ind.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_a = torch.ones(N)\n",
    "temp_b = torch.cat((torch.ones(N//2), torch.zeros(N//2)))\n",
    "matches = torch.logical_and(temp_a, temp_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = torch.cat((first_ind[:, matches], second_ind[:, matches])) # must-link constraints\n",
    "D = torch.cat((first_ind[:, torch.logical_not(matches)], second_ind[:, torch.logical_not(matches)])) # cannot-link constraints"
   ]
  },
  {
   "source": [
    "### kernel matrix "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prime = torch.square(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 1264])\n"
     ]
    }
   ],
   "source": [
    "n1sq = torch.sum(input=X_prime, dim=0, keepdim=True)\n",
    "print(n1sq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1264\n"
     ]
    }
   ],
   "source": [
    "n1 = n1sq.shape[1]\n",
    "print(n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_a = torch.ones(n1, 1)*n1sq\n",
    "k = torch.matmul(X.T,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = temp_a.T + temp_a -2*k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-7.2760e-12,  5.3505e+04,  2.1090e+04,  2.0321e+04,  6.4775e+04,\n",
       "         5.1881e+04,  2.3210e+04,  3.6540e+04,  3.1457e+04,  6.2572e+04,\n",
       "         3.2691e+04,  5.0277e+04,  2.8126e+04,  2.5026e+04,  3.2841e+04,\n",
       "         3.2291e+04,  4.9261e+04,  2.7565e+04,  7.7478e+04,  2.6836e+04,\n",
       "         2.6782e+04,  5.6574e+04,  3.5294e+04,  2.9626e+04,  4.3649e+04,\n",
       "         1.2709e+04,  3.4817e+04,  4.8167e+04,  2.3792e+04,  2.3762e+04,\n",
       "         2.6439e+04,  3.4606e+04,  4.1348e+04,  2.6597e+04,  2.6235e+04,\n",
       "         3.3001e+04,  3.0693e+04,  2.0489e+04,  3.5547e+04,  2.2149e+04,\n",
       "         4.9874e+04,  1.5828e+04,  2.9480e+04,  1.8876e+04,  2.7942e+04,\n",
       "         2.8193e+04,  2.6190e+04,  2.1829e+04,  2.9023e+04,  2.2499e+04,\n",
       "         3.1487e+04,  3.5080e+04,  3.5754e+04,  5.4332e+04,  2.9127e+04,\n",
       "         2.1017e+04,  3.1802e+04,  2.8393e+04,  2.2043e+04,  2.4091e+04,\n",
       "         2.3579e+04,  2.8748e+04,  1.9351e+04,  2.5617e+04,  4.2532e+04,\n",
       "         3.4165e+04,  2.1329e+04,  2.4348e+04,  5.0737e+04,  4.4834e+04,\n",
       "         7.9719e+04,  5.2066e+04,  5.6264e+04,  4.8532e+04,  8.6568e+04,\n",
       "         6.1675e+04,  7.3378e+04,  6.5019e+04,  8.0214e+04,  7.6677e+04,\n",
       "         5.6095e+04,  7.2439e+04,  9.8995e+04,  8.0535e+04,  5.9652e+04,\n",
       "         5.6889e+04,  7.1990e+04,  6.8480e+04,  7.2007e+04,  5.9099e+04,\n",
       "         5.1471e+04,  7.3895e+04,  5.0710e+04,  5.4861e+04,  4.1026e+04,\n",
       "         4.6042e+04,  5.8927e+04,  5.3059e+04,  7.7096e+04,  4.1202e+04],\n",
       "       dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "K[0:100,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-7.2760e-12,  5.3505e+04,  2.1090e+04,  2.0321e+04,  6.4775e+04,\n",
       "         5.1881e+04,  2.3210e+04,  3.6540e+04,  3.1457e+04,  6.2572e+04,\n",
       "         3.2691e+04,  5.0277e+04,  2.8126e+04,  2.5026e+04,  3.2841e+04,\n",
       "         3.2291e+04,  4.9261e+04,  2.7565e+04,  7.7478e+04,  2.6836e+04,\n",
       "         2.6782e+04,  5.6574e+04,  3.5294e+04,  2.9626e+04,  4.3649e+04,\n",
       "         1.2709e+04,  3.4817e+04,  4.8167e+04,  2.3792e+04,  2.3762e+04,\n",
       "         2.6439e+04,  3.4606e+04,  4.1348e+04,  2.6597e+04,  2.6235e+04,\n",
       "         3.3001e+04,  3.0693e+04,  2.0489e+04,  3.5547e+04,  2.2149e+04,\n",
       "         4.9874e+04,  1.5828e+04,  2.9480e+04,  1.8876e+04,  2.7942e+04,\n",
       "         2.8193e+04,  2.6190e+04,  2.1829e+04,  2.9023e+04,  2.2499e+04,\n",
       "         3.1487e+04,  3.5080e+04,  3.5754e+04,  5.4332e+04,  2.9127e+04,\n",
       "         2.1017e+04,  3.1802e+04,  2.8393e+04,  2.2043e+04,  2.4091e+04,\n",
       "         2.3579e+04,  2.8748e+04,  1.9351e+04,  2.5617e+04,  4.2532e+04,\n",
       "         3.4165e+04,  2.1329e+04,  2.4348e+04,  5.0737e+04,  4.4834e+04,\n",
       "         7.9719e+04,  5.2066e+04,  5.6264e+04,  4.8532e+04,  8.6568e+04,\n",
       "         6.1675e+04,  7.3378e+04,  6.5019e+04,  8.0214e+04,  7.6677e+04,\n",
       "         5.6095e+04,  7.2439e+04,  9.8995e+04,  8.0535e+04,  5.9652e+04,\n",
       "         5.6889e+04,  7.1990e+04,  6.8480e+04,  7.2007e+04,  5.9099e+04,\n",
       "         5.1471e+04,  7.3895e+04,  5.0710e+04,  5.4861e+04,  4.1026e+04,\n",
       "         4.6042e+04,  5.8927e+04,  5.3059e+04,  7.7096e+04,  4.1202e+04],\n",
       "       dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "temp_a = torch.matmul(torch.ones(n1, 1).double(), n1sq.double())\n",
    "k = torch.matmul(X.T,X)\n",
    "K = temp_a.T + temp_a -2*k\n",
    "K[0:100, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.4420, 0.7248,  ..., 0.5190, 0.5430, 0.6114],\n",
       "        [0.4420, 1.0000, 0.4973,  ..., 0.2241, 0.3023, 0.3958],\n",
       "        [0.7248, 0.4973, 1.0000,  ..., 0.3980, 0.6200, 0.4984],\n",
       "        ...,\n",
       "        [0.5190, 0.2241, 0.3980,  ..., 1.0000, 0.5520, 0.3951],\n",
       "        [0.5430, 0.3023, 0.6200,  ..., 0.5520, 1.0000, 0.5055],\n",
       "        [0.6114, 0.3958, 0.4984,  ..., 0.3951, 0.5055, 1.0000]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "torch.exp(-torch.mul(K,sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.4420, 0.7248, 0.7334, 0.3722, 0.4531, 0.7018, 0.5726, 0.6188,\n",
       "        0.3849, 0.6072, 0.4643, 0.6511, 0.6826, 0.6059, 0.6110, 0.4716, 0.6566,\n",
       "        0.3066, 0.6640, 0.6645, 0.4218, 0.5836, 0.6363, 0.5137, 0.8237, 0.5879,\n",
       "        0.4795, 0.6956, 0.6959, 0.6680, 0.5898, 0.5321, 0.6664, 0.6701, 0.6044,\n",
       "        0.6260, 0.7315, 0.5814, 0.7132, 0.4672, 0.7854, 0.6377, 0.7497, 0.6529,\n",
       "        0.6504, 0.6706, 0.7167, 0.6422, 0.7094, 0.6185, 0.5855, 0.5795, 0.4365,\n",
       "        0.6412, 0.7256, 0.6155, 0.6484, 0.7144, 0.6924, 0.6978, 0.6449, 0.7443,\n",
       "        0.6765, 0.5226, 0.5937, 0.7222, 0.6897, 0.4611, 0.5045, 0.2963, 0.4518,\n",
       "        0.4238, 0.4769, 0.2669, 0.3902, 0.3264, 0.3708, 0.2941, 0.3104, 0.4249,\n",
       "        0.3311, 0.2208, 0.2926, 0.4024, 0.4198, 0.3334, 0.3517, 0.3333, 0.4058,\n",
       "        0.4559, 0.3238, 0.4613, 0.4330, 0.5347, 0.4953, 0.4069, 0.4450, 0.3084,\n",
       "        0.5333], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "from kernelmatrix import kernelmatrix\n",
    "k = kernelmatrix(X,torch.tensor([]),2**-16)\n",
    "k[0:100,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.4420, 0.7248, 0.7334, 0.3722, 0.4531, 0.7018, 0.5726, 0.6188,\n",
       "        0.3849, 0.6072, 0.4643, 0.6511, 0.6826, 0.6059, 0.6110, 0.4716, 0.6566,\n",
       "        0.3066, 0.6640, 0.6645, 0.4218, 0.5836, 0.6363, 0.5137, 0.8237, 0.5879,\n",
       "        0.4795, 0.6956, 0.6959, 0.6680, 0.5898, 0.5321, 0.6664, 0.6701, 0.6044,\n",
       "        0.6260, 0.7315, 0.5814, 0.7132, 0.4672, 0.7854, 0.6377, 0.7497, 0.6529,\n",
       "        0.6504, 0.6706, 0.7167, 0.6422, 0.7094, 0.6185, 0.5855, 0.5795, 0.4365,\n",
       "        0.6412, 0.7256, 0.6155, 0.6484, 0.7144, 0.6924, 0.6978, 0.6449, 0.7443,\n",
       "        0.6765, 0.5226, 0.5937, 0.7222, 0.6897, 0.4611, 0.5045, 0.2963, 0.4518,\n",
       "        0.4238, 0.4769, 0.2669, 0.3902, 0.3264, 0.3708, 0.2941, 0.3104, 0.4249,\n",
       "        0.3311, 0.2208, 0.2926, 0.4024, 0.4198, 0.3334, 0.3517, 0.3333, 0.4058,\n",
       "        0.4559, 0.3238, 0.4613, 0.4330, 0.5347, 0.4953, 0.4069, 0.4450, 0.3084,\n",
       "        0.5333], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "from kernelmatrix import kernelmatrix\n",
    "k = kernelmatrix(X, torch.tensor([]), sigma=2**-16)\n",
    "k[0:100,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([-0.7315+0.8825j,  0.3158-0.6901j, -0.4278+0.3406j, -0.3595+0.1549j])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(4, dtype=torch.cfloat)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-0.7315,  0.3158, -0.4278, -0.3595])"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "torch.real(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "torch.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 1.3994, -1.3419,  0.5751,  0.5541],\n        [ 0.0387, -1.4174, -0.4893, -1.4307],\n        [-1.8589, -0.4220,  0.9139,  0.3833],\n        [ 0.4520, -0.4995,  1.0232, -1.1044]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4,4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 0.1970, -0.1315, -0.3570,  0.1453],\n        [-0.3622, -0.3750, -0.2256,  0.2258],\n        [ 0.0944, -0.3523,  0.2033,  0.5743],\n        [ 0.3319, -0.2105,  0.1443, -0.4161]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.inverse(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.matmul(x.float(),y.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = lambda x: torch.cos(x)-x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-0.7858],\n        [ 0.3615],\n        [-0.8102],\n        [-0.9178],\n        [-0.5415],\n        [-1.9918],\n        [-0.2777],\n        [ 1.7436],\n        [ 0.0844],\n        [-0.1833]])\n\ntensor([[ 0.0894],\n        [ 0.8047],\n        [ 0.0329],\n        [-0.2347],\n        [ 0.5638],\n        [-4.3758],\n        [ 0.8846],\n        [-3.2121],\n        [ 0.9893],\n        [ 0.9496]])\n"
     ]
    }
   ],
   "source": [
    "v = torch.randn(10,1)\n",
    "print(v)\n",
    "print()\n",
    "print(b(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 1.]])"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "x = torch.zeros(3,3)\n",
    "x[torch.randn(3,3) > 0.5] = 1\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "torch.count_nonzero(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0, 2, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "torch.count_nonzero(x, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "ib = D[0,:].view(1,316)\n",
    "ie = D[1,:].view(1,316)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 316])\n"
     ]
    }
   ],
   "source": [
    "print(ib.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrayfun = lambda x: torch.count_nonzero(x==ib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(316)"
      ]
     },
     "metadata": {},
     "execution_count": 116
    }
   ],
   "source": [
    "arrayfun(ib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = ib[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}